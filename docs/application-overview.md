# StudiumPlus Partner-Notizen - Applikations√ºbersicht

> **‚ö†Ô∏è WICHTIG - Kostenmanagement:**
> Diese Dokumentation enth√§lt eine wichtige Sektion zur **Token-Optimierung & Kostenmanagement** (siehe unten).
> Die implementierte Feld-Filterung beim Company-Matching reduziert API-Kosten deutlich (>90%) und ist essentiell f√ºr den wirtschaftlichen Betrieb.

## Zweck der Anwendung

Die StudiumPlus Partner-Notizen App ist eine Progressive Web Application (PWA), die StudiumPlus-Direktoren bei der Dokumentation von Partnergespr√§chen unterst√ºtzt. Die App automatisiert den Workflow von der Sprachaufnahme bis zum fertigen GitHub Issue durch den Einsatz von KI-Technologien.

### Hauptziele

1. **Schnelle Erfassung**: Gespr√§chsnotizen per Sprachaufnahme direkt nach Partnergespr√§chen aufnehmen
2. **Automatische Verarbeitung**: KI-gest√ºtzte Transkription und professionelle Textaufbereitung
3. **Zentrale Dokumentation**: Automatische Erstellung von GitHub Issues als zentrale Wissensdatenbank
4. **Offline-f√§hig**: Nutzung auch ohne Internetverbindung, Synchronisation erfolgt sp√§ter

## Technologie-Stack

### Frontend
- **Vue.js 3** mit Composition API - Modernes reaktives Framework
- **TypeScript** - Typsicherheit und bessere Developer Experience
- **Vuetify 3** - Material Design Komponenten-Bibliothek
- **Vue Router** - Client-seitige Navigation

### State Management & Storage
- **Pinia** - Zentrales State Management f√ºr Vue 3
- **IndexedDB** (via Dexie.js) - Lokale Datenspeicherung im Browser
- **LocalStorage** - Verschl√ºsselte Speicherung von API-Keys

### Build & Development
- **Vite** - Schneller Build-Tool und Dev-Server
- **vite-plugin-pwa** - PWA-Funktionalit√§t mit Service Worker
- **TypeScript Compiler** - Type-Checking

### APIs & Services
- **OpenAI Whisper API** - Sprachtranskription (Audio ‚Üí Text)
- **OpenAI GPT-5-mini** - Textaufbereitung und Company-Matching
- **GitHub API** - Issue-Erstellung und Datenabfrage

### Sicherheit
- **WebAuthn** - Biometrische Authentifizierung (Fingerprint, FaceID)
- **crypto-js** - AES-Verschl√ºsselung f√ºr sensible Daten

## Architektur-√úbersicht

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         PWA Frontend                         ‚îÇ
‚îÇ                    (Vue.js + TypeScript)                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ   Views      ‚îÇ  ‚îÇ  Composables ‚îÇ  ‚îÇ   Stores     ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  (Pages)     ‚îÇ  ‚îÇ  (Logic)     ‚îÇ  ‚îÇ   (State)    ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ              Services (API Layer)                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ OpenAI   ‚îÇ  ‚îÇ  GitHub  ‚îÇ  ‚îÇ  DB      ‚îÇ           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Service  ‚îÇ  ‚îÇ  Service ‚îÇ  ‚îÇ  Service ‚îÇ           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ              Storage Layer                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  IndexedDB   ‚îÇ          ‚îÇ LocalStorage ‚îÇ          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  (Dexie.js)  ‚îÇ          ‚îÇ (encrypted)  ‚îÇ          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚îÇ HTTPS
                            ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ       External Services             ‚îÇ
        ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
        ‚îÇ  OpenAI API    ‚îÇ  GitHub API        ‚îÇ
        ‚îÇ  - Whisper     ‚îÇ  - Issues          ‚îÇ
        ‚îÇ  - GPT-5-mini  ‚îÇ  - Contents        ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Hauptkomponenten

### Views (Seiten)

| View | Route | Beschreibung |
|------|-------|--------------|
| **OnboardingView** | `/onboarding` | Erstmaliges Setup: Name, API-Keys, GitHub Token |
| **AuthView** | `/auth` | WebAuthn Login-Bildschirm |
| **HomeView** | `/` | Dashboard mit letzten Notizen |
| **RecordingView** | `/recording` | Sprachaufnahme-Interface |
| **PreviewView** | `/preview/:id` | Bearbeitung von Transkription und aufbereitetem Text |
| **HistoryView** | `/history` | √úbersicht aller Notizen mit Filter |
| **SettingsView** | `/settings` | Einstellungen (API-Keys, Auto-Lock, Daten-Export) |

### Stores (Pinia)

| Store | Verantwortlichkeit |
|-------|-------------------|
| **authStore** | Authentifizierung, API-Keys, User-Daten |
| **voiceNotesStore** | CRUD-Operationen f√ºr Sprachnotizen |
| **companiesStore** | Verwaltung der Partnerunternehmen-Daten |
| **settingsStore** | App-Einstellungen (Auto-Lock, Theme) |
| **notificationStore** | Toast-Benachrichtigungen |

### Services

| Service | Datei | Beschreibung |
|---------|-------|--------------|
| **OpenAI Service** | `src/services/openai.service.ts` | Whisper-Transkription, GPT-Textaufbereitung, Company-Matching |
| **GitHub Service** | `src/services/github.service.ts` | Issue-Erstellung, Abruf von `companies.json` |
| **DB Service** | `src/services/db.ts` | IndexedDB-Zugriff (Dexie.js Schema) |
| **Encryption Service** | `src/services/encryption.service.ts` | AES-Verschl√ºsselung f√ºr API-Keys |

### Composables

| Composable | Datei | Beschreibung |
|------------|-------|--------------|
| **useProcessing** | `src/composables/useProcessing.ts` | Zentrale Verarbeitungslogik: Transkription, Aufbereitung, GitHub-Versand |
| **useOfflineSync** | `src/composables/useOfflineSync.ts` | Offline-Synchronisation und Retry-Mechanismen |

## Verarbeitungs-Pipeline

Die Verarbeitung einer Notiz durchl√§uft mehrere Phasen. Details zu den Status-√úberg√§ngen finden sich in der [Note Status Model Dokumentation](./note-status-model.md).

### 1. Aufnahme (Recording)

**Komponente:** `RecordingView.vue`

```
User dr√ºckt Record-Button
    ‚Üì
MediaRecorder API startet Aufnahme
    ‚Üì
Audio-Chunks werden gesammelt
    ‚Üì
User stoppt Aufnahme
    ‚Üì
Blob wird in IndexedDB gespeichert
    ‚Üì
Status: RECORDED
```

### 2. Transkription

**Service:** `openai.service.ts:transcribeAudio()`
**Trigger:** User klickt "Transkribieren" oder automatisch nach Aufnahme

```
Status: RECORDED ‚Üí TRANSCRIBING
    ‚Üì
Audio Blob ‚Üí FormData (MP3)
    ‚Üì
POST /v1/audio/transcriptions (OpenAI Whisper)
    ‚Üì
Response: { text: "..." }
    ‚Üì
Text wird gespeichert
    ‚Üì
Status: TRANSCRIBED
```

**Fehlerbehandlung:** Bei API-Fehler ‚Üí Status `ERROR` mit Fehlermeldung

### 3. Company-Matching (Optional, automatisch)

**Service:** `openai.service.ts:matchCompany()`
**Trigger:** Automatisch nach Transkription

```
Transkription + companies.json werden an GPT-5-mini gesendet
    ‚Üì
Nur matching-relevante Felder werden extrahiert:
  ‚Ä¢ id, name, shortName, aliases, location
  ‚Ä¢ KEINE Kontakt-Daten (nicht relevant f√ºr Firmen-Matching)
  ‚Ä¢ Reduziert Token-Verbrauch um ~70-80%
    ‚Üì
KI analysiert Text und findet erw√§hntes Unternehmen
    ‚Üì
Response: { matched_company_id: "...", confidence: "high/medium/low" }
    ‚Üì
Company/Contact werden vorausgew√§hlt
```

**Hinweise:**
- Nicht kritisch - User kann Company manuell w√§hlen, falls Matching fehlschl√§gt
- Token-Optimierung: Nur 5 Felder pro Firma werden gesendet
- Funktioniert effizient auch bei vielen Unternehmen

### 4. Textaufbereitung

**Service:** `openai.service.ts:processText()`
**Trigger:** User w√§hlt Company/Contact und klickt "Verarbeiten"

```
Status: TRANSCRIBED ‚Üí PROCESSING
    ‚Üì
Transkription + Company + Contact ‚Üí GPT-5-mini
    ‚Üì
KI strukturiert den Text nach klaren Regeln:
  - INHALTLICHE TREUE: Keine √Ñnderung von Aussagen
  - MINIMALE KORREKTUR: Nur Grammatik & Rechtschreibung
  - GESPR√ÑCHSDATUM-ERKENNUNG: Explizite Extraktion des Gespr√§chsdatums (nicht Aufzeichnungsdatum!)
  - DEADLINE-ERKENNUNG: Extraktion aller Termine/Fristen
  - STRUKTURIERUNG: Gliederung in Abschnitte
    ‚Ä¢ Gespr√§chsdatum (dedizierte Extraktion)
    ‚Ä¢ Gespr√§chsnotizen (originalgetreu)
    ‚Ä¢ Vereinbarungen
    ‚Ä¢ Deadlines & Termine (zuk√ºnftige Termine)
    ‚Ä¢ N√§chste Schritte
    ‚Üì
Response: Strukturierter Text (Originalaussagen erhalten)
    ‚Üì
Status: PROCESSED
```

**GPT-Prompt-Regeln:**
- Bewahrt inhaltliche Aussagen (keine Interpretationen)
- Korrigiert nur offensichtliche Fehler
- **Extrahiert Gespr√§chsdatum explizit** (Regel 5: sucht nach "Gespr√§ch am...", "heute", etc.)
- Extrahiert alle Termine/Deadlines in Format TT.MM.JJJJ
- Verwendet m√∂glichst Originalwortlaut

### 5. GitHub Issue-Erstellung

**Service:** `github.service.ts:createIssue()`
**Trigger:** User klickt "An GitHub senden"

```
Status: PROCESSED ‚Üí SENDING
    ‚Üì
Formatierung des Issue-Body:
  - Titel: [Company] - Datum - User
  - Body: Markdown mit Metadaten + aufbereitetem Text
  - Labels: partner-kontakt, company-slug
    ‚Üì
POST /repos/{owner}/{repo}/issues (GitHub API)
    ‚Üì
Response: { html_url, number }
    ‚Üì
URL & Issue-Nummer werden gespeichert
    ‚Üì
Status: SENT
```

**Issue-Format:**
```markdown
## Metadaten
- **Unternehmen:** ABC GmbH
- **Ansprechpartner:** Max Mustermann (Gesch√§ftsf√ºhrer)
- **Datum:** 21.11.2025
- **Erfasst von:** John Doe

## Gespr√§chsnotiz
[Aufbereiteter Text von GPT]
```

## Token-Optimierung & Kostenmanagement

**‚ö†Ô∏è WICHTIG:** Die Anzahl der an OpenAI gesendeten Tokens hat direkten Einfluss auf die API-Kosten. Besonders beim Company-Matching kann eine naive Implementierung sehr teuer werden.

### Problem: Company-Matching mit gro√üen Datens√§tzen

**Szenario:** Bei vielen Unternehmen w√ºrde eine naive Implementierung alle Daten senden:
```
1 Unternehmen mit allen Feldern (inkl. Kontakte, Notes, etc.): ~200-500 tokens
100 Unternehmen: ~20.000-50.000 tokens pro Anfrage
1000 Unternehmen: ~200.000-500.000 tokens pro Anfrage ‚ùå (√ºberschreitet Context Window!)
```

**Kosten-Beispiel (GPT-5-mini) bei naiver Implementierung:**
- Input: $0.25 per 1M tokens
- Output: $2.00 per 1M tokens
- Bei 100 Anfragen/Tag mit 50.000 tokens Input: 0.05M √ó $0.25 √ó 100 Tage = ~$1.25/Tag
- = ~$450/Jahr nur f√ºr Company-Matching (ohne Output!) ‚ùå

### Implementierte L√∂sung: Feld-Filterung (Option 1)

**Aktueller Ansatz in `openai.service.ts:matchCompany()`:**

Die Funktion extrahiert automatisch nur matching-relevante Felder, bevor Daten an die API gesendet werden:

```typescript
// Nur 5 relevante Felder pro Unternehmen
const compactCompanies = companies.companies?.map((c: any) => ({
  id: c.id,              // F√ºr R√ºckmeldung n√∂tig
  name: c.name,          // Prim√§res Matching-Kriterium
  shortName: c.shortName,// H√§ufig verwendet in Gespr√§chen
  aliases: c.aliases,    // Wichtig f√ºr Varianten (z.B. "Viessmann" vs "Viessmann Group")
  location: c.location   // Optional, falls Standort erw√§hnt wird
}))
```

**Ausgeschlossene Felder (nicht relevant f√ºr Firmen-Matching):**
- ‚ùå `contacts[]` - Ansprechpartner (gr√∂√üter Token-Verbraucher!)
- ‚ùå `studyPrograms[]` - Nicht relevant f√ºr Identifikation
- ‚ùå `notes` - Zu viele Tokens
- ‚ùå `partnershipType` - Nicht relevant f√ºr Matching
- ‚ùå `lastContactDate` - Nicht relevant f√ºr Matching

**Effekt:**
- **Token-Reduktion: ~70-80%**
- 1 Unternehmen: ~50-100 tokens (statt 200-500)
- 100 Unternehmen: ~5.000-10.000 tokens ‚úÖ
- 1000 Unternehmen: ~50.000-100.000 tokens ‚úÖ

**Kostenersparnis durch Feld-Filterung:**
- Mit Optimierung: ~$0.21/Monat = ~$2.50/Jahr f√ºr Matching
- Ohne Optimierung (naive Implementierung): ~$450/Jahr
- **Einsparung: ~99.4% (~$447/Jahr)** üéØ

### Alternative Ans√§tze (f√ºr Zukunft dokumentiert)

#### Option 2: Pre-Filtering (f√ºr sehr gro√üe Datens√§tze)

```typescript
// Im Frontend: Erst Keyword-Extraktion
const keywords = extractKeywords(transcription)
const relevantCompanies = companies.filter(c =>
  keywords.some(kw =>
    c.name.toLowerCase().includes(kw.toLowerCase()) ||
    c.aliases.some(a => a.toLowerCase().includes(kw.toLowerCase()))
  )
)

// Nur 10-50 relevante Firmen an API senden
await matchCompany(transcription, relevantCompanies, apiKey)
```

**Vorteile:**
- Weitere Token-Reduktion: ~90-95%
- Schnellere API-Antworten

**Nachteile:**
- Komplexere Logik
- Risiko: Relevante Firma wird vorab ausgefiltert

#### Option 3: Zwei-Stufen-Ansatz

1. **Stufe 1:** Nur Namen an GPT senden ‚Üí Kandidaten-Liste
2. **Stufe 2:** Details aus lokalem Cache laden

**Vorteile:**
- Minimale Tokens (~10-20 pro Firma)

**Nachteile:**
- 2 API-Calls (mehr Latenz)
- Komplexere Implementierung

#### Option 4: Vector Search / Embeddings

Embeddings-basierte Suche f√ºr semantisches Matching ohne gro√üe Prompts.

**Vorteile:**
- Extrem effizient bei >1000 Firmen
- Einmalige Embedding-Kosten

**Nachteile:**
- Hohe Komplexit√§t
- Zus√§tzliche Infrastruktur n√∂tig

### Empfohlene Strategie

**Aktuell (< 500 Unternehmen):**
- ‚úÖ **Option 1** (Feld-Filterung) - bereits implementiert
- ‚úÖ **Zus√§tzlich:** Manuelle Vorauswahl in companies.json (nur wichtige Partner)

**Zuk√ºnftig (> 500 Unternehmen):**
- üîÑ **Option 2** (Pre-Filtering) hinzuf√ºgen
- üîÑ **Oder** Option 3 (Zwei-Stufen) f√ºr maximale Effizienz

### Monitoring & Best Practices

**Token-Verbrauch √ºberwachen:**
```typescript
// Optional: Token-Z√§hlung loggen
console.log(`Sent ${compactJson.length} characters (~${compactJson.length/4} tokens)`)
```

**Kostenoptimierung:**
- companies.json klein halten (nur aktive Partner)
- Regelm√§√üig alte/inaktive Firmen entfernen
- Bei Bedarf: Caching f√ºr h√§ufige Matches

**Gesch√§tzte Gesamtkosten (bei 100 Notizen/Monat):**

*Pricing-Annahmen (Stand: OpenAI GPT-5-mini Preise):*
- Whisper: $0.006 per Minute Audio
- GPT-5-mini Input: $0.25 per 1M tokens
- GPT-5-mini Cached Input: $0.25 per 1M tokens
- GPT-5-mini Output: $2.00 per 1M tokens

*Berechnungen:*
1. **Whisper (Transkription):**
   - 100 Notizen √ó 3 Min √ò = 300 Min/Monat
   - 300 Min √ó $0.006 = **~$1.80/Monat**

2. **GPT-5-mini (Company Matching):**
   - 100 Anfragen √ó 7.500 tokens Input (√ò) = 750k tokens
   - 100 Anfragen √ó 100 tokens Output (√ò) = 10k tokens
   - Input: 0.75M √ó $0.25 = $0.19
   - Output: 0.01M √ó $2.00 = $0.02
   - **~$0.21/Monat**

3. **GPT-5-mini (Textaufbereitung):**
   - 100 Anfragen √ó 1.000 tokens Input (√ò) = 100k tokens
   - 100 Anfragen √ó 800 tokens Output (√ò) = 80k tokens
   - Input: 0.1M √ó $0.25 = $0.025
   - Output: 0.08M √ó $2.00 = $0.16
   - **~$0.19/Monat**

**Total: ~$2.20/Monat oder ~$26/Jahr** ‚úÖ

*Hinweis: Preise Stand August 2025 (GPT-5-mini Release). Aktuelle Preise pr√ºfen unter: https://openai.com/pricing*

---

## Datenfluss

### Lokale Datenhaltung

**IndexedDB (via Dexie.js):**
```typescript
// Schema in src/services/db.ts
{
  voiceNotes: {
    id: string (nanoid)
    audioBlob: Blob
    transcription?: string
    processedText?: string
    selectedCompanyId?: string
    selectedContactId?: string
    recordedAt: Date
    status: NoteStatus
    errorMessage?: string
    githubIssueUrl?: string
    githubIssueNumber?: number
  }
}
```

**LocalStorage (verschl√ºsselt):**
```json
{
  "auth_data": "<AES-verschl√ºsseltes JSON>",
  "settings": {
    "autoLockMinutes": 15
  }
}
```

### API-Kommunikation

**OpenAI API:**
- Endpoint: `https://api.openai.com/v1`
- Authentifizierung: `Bearer <API-Key>`
- Verwendete Modelle:
  - `whisper-1` - Transkription
  - `gpt-5-mini` - Textaufbereitung und Matching

**GPT-5 API-Unterschiede:**
- ‚ö†Ô∏è Verwendet `max_completion_tokens` statt `max_tokens`
- ‚ö†Ô∏è `temperature` Parameter nicht unterst√ºtzt (nur Standard-Wert 1)
- ‚ö†Ô∏è Unterschiedliche Token-Limits: 272k Input, 128k Output (inkl. Reasoning)

**GitHub API:**
- Endpoint: `https://api.github.com`
- Authentifizierung: `token <GitHub-PAT>`
- Verwendete Endpoints:
  - `POST /repos/{owner}/{repo}/issues` - Issue erstellen
  - `GET /repos/{owner}/{repo}/contents/companies.json` - Unternehmensdaten
- Hinweis: User-Agent Header kann in Browsern nicht gesetzt werden (Sicherheitsrestriktion)

## Sicherheitskonzept

### Authentifizierung

**WebAuthn (biometrisch):**
- Fingerabdruck (iOS, Android, Windows Hello)
- FaceID (iOS, macOS)
- PIN als Fallback
- Challenge-Response-Mechanismus
- Credentials werden im Browser gespeichert (nicht √ºbertragbar)

**Implementierung:** `src/stores/auth.ts`

### Datenverschl√ºsselung

**API-Keys (AES-256):**
```typescript
// Verschl√ºsselung
const encrypted = CryptoJS.AES.encrypt(apiKey, passphrase).toString()

// Entschl√ºsselung
const decrypted = CryptoJS.AES.decrypt(encrypted, passphrase).toString(CryptoJS.enc.Utf8)
```

**Passphrase-Generierung:** Aus WebAuthn-Challenge abgeleitet

### Auto-Lock

- Automatisches Logout nach konfigurierbarer Inaktivit√§t (1, 5, 15 Min oder Aus)
- Bei Verlassen der App (Tab-Wechsel, App in Hintergrund)
- Implementierung: `src/composables/useAutoLock.ts`

## Offline-Funktionalit√§t

### Service Worker

**Caching-Strategie:**
- **App-Shell:** Precaching aller statischen Assets (HTML, CSS, JS, Fonts)
- **Runtime-Caching:** API-Responses (stale-while-revalidate)
- **IndexedDB:** Alle Notizen und Audio-Daten

**Offline-F√§higkeiten:**
- Sprachaufnahme funktioniert komplett offline
- Notizen werden lokal gespeichert
- Verarbeitung erfordert Internet (OpenAI/GitHub APIs)

### Synchronisation

**Implementierung:** `src/composables/useOfflineSync.ts`

```
App startet / Kommt online
    ‚Üì
Pr√ºfe alle Notizen mit Status PROCESSED
    ‚Üì
Finde Notizen ohne GitHub Issue URL
    ‚Üì
Versuche automatisch, Issues zu erstellen
    ‚Üì
Bei Erfolg: Status ‚Üí SENT
Bei Fehler: Status bleibt PROCESSED (erneuter Versuch beim n√§chsten Online-Event)
```

## Workflow-Beispiel

**Typischer User-Workflow:**

1. **Login**
   - App √∂ffnen ‚Üí WebAuthn-Authentifizierung (Fingerprint)

2. **Aufnahme**
   - "Neue Aufnahme" ‚Üí Aufnahme-Button dr√ºcken
   - Gespr√§chsnotiz sprechen
   - Aufnahme stoppen ‚Üí Automatische Transkription startet

3. **Bearbeitung**
   - Transkription erscheint
   - Company wird (meist) automatisch erkannt
   - Optional: Company/Contact manuell korrigieren
   - "Verarbeiten" ‚Üí KI bereitet Text auf

4. **Review & Senden**
   - Aufbereiteten Text pr√ºfen
   - Optional: Nachbearbeitung
   - "An GitHub senden" ‚Üí Issue wird erstellt

5. **Fertig**
   - GitHub Issue-URL wird angezeigt
   - Notiz hat Status "Gesendet"
   - In Historie abrufbar

**Zeitaufwand:** Ca. 30-60 Sekunden vom Start bis zum fertigen Issue (ohne Aufnahmezeit)

## Fehlerbehandlung

### API-Fehler

**Retry-Mechanismus:**
- Automatische Wiederholung bei Netzwerkfehlern
- Exponential Backoff: 2s, 4s, 8s, 16s
- Max. 4 Versuche
- Implementierung in allen API-Services

**User-Feedback:**
- Toast-Benachrichtigungen bei Fehlern
- Detaillierte Fehlermeldung im ERROR-Status
- "Erneut versuchen"-Button in HistoryView

### Offline-Handling

- Pr√ºfung auf Internet-Verbindung vor API-Calls
- Benachrichtigung: "Keine Internetverbindung"
- Notizen bleiben in lokalem Status (RECORDED, TRANSCRIBED, PROCESSED)
- Automatische Synchronisation bei Wiederverbindung

## Performance-Optimierungen

### Lazy Loading

- Route-basiertes Code-Splitting
- Komponenten werden nur geladen, wenn ben√∂tigt
- Reduzierte initiale Bundle-Gr√∂√üe

### Audio-Kompression

- Aufnahme in WebM/Opus oder MP4/AAC
- Konvertierung zu MP3 f√ºr OpenAI
- Blob-URLs f√ºr effiziente Speicherung

### IndexedDB

- Asynchrone Operationen (kein Blocking der UI)
- Indexed Queries f√ºr schnelle Suche
- Automatisches Cleanup von Blob-URLs

## Erweiterbarkeit

### Geplante Features

- **Team-Funktionalit√§t:** Mehrere User, Notizen teilen
- **Templates:** Vordefinierte Gespr√§chsstrukturen
- **Export:** PDF-Export von Notizen
- **Statistiken:** √úbersicht √ºber Gespr√§che pro Unternehmen
- **Sprach-Unterst√ºtzung:** Mehrsprachigkeit (aktuell nur Deutsch)

### Extension Points

1. **Neue Status:** Erweiterung des `NoteStatus` Enums
2. **Neue Verarbeitungsschritte:** Hooks in `useProcessing.ts`
3. **Weitere AI-Features:** Sentiment-Analyse, Zusammenfassungen
4. **Integration:** Weitere Issue-Tracker (Jira, Linear, etc.)

## Entwickler-Hinweise

### Setup f√ºr lokale Entwicklung

```bash
# Dependencies installieren
npm install

# .env.local erstellen
cp .env.example .env.local

# Dev-Server starten
npm run dev

# TypeScript pr√ºfen
npm run build

# Tests ausf√ºhren
npm run test
```

### Wichtige Konventionen

1. **Composables:** Wiederverwendbare Logik mit `use*` Prefix
2. **Services:** Pure Functions, keine Vue-Dependencies
3. **Stores:** Minimale Business-Logik, haupts√§chlich State
4. **Error-Handling:** Immer try/catch bei async Operations
5. **TypeScript:** Keine `any` Types, vollst√§ndige Typisierung

### Debugging

- **Vue DevTools:** Pinia State, Component Tree
- **IndexedDB:** Chrome DevTools ‚Üí Application ‚Üí IndexedDB
- **Service Worker:** Chrome DevTools ‚Üí Application ‚Üí Service Workers
- **Network:** Alle API-Calls in Network-Tab sichtbar

## Weitere Dokumentation

- [Note Status Model](./note-status-model.md) - Details zum Status-Management
- [README.md](../README.md) - Setup und Installation
